import streamlit as st
import pandas as pd
from utils.pipeline import evaluate_models, evaluate_models_optimisation, importance_features
import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay
from io import BytesIO
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from utils.pipeline import ready_to_process_data_advanced

def show_modelisation():

    st.title("Mod√©lisation")
    tab1, tab2 = st.tabs(["Premi√®res it√©rations et interpr√©tation", "Optimisations"])
    
    with tab1:
        st.subheader("√âvaluation des mod√®les et performances")

        # √âvaluation
        results_df, reports, matrices, models = evaluate_models()

        # Tableau r√©capitulatif
        st.dataframe(results_df, use_container_width = True)

        st.markdown("""
        - Il y a beaucoup d'overfitting sur le random forest et le decision tree
        - On remarque que le mod√®le pr√©dit mieux les clients qui ne soucriront pas (classe 0) que ceux qui souscriront
        - Il est possible de se focaliser sur la r√©duction des faux positifs (afin de ne pas contacter inutilement des gens qui ne souscriront pas) mais il semble √©galement pertinent de r√©duire les faux n√©gatifs (afin de ne pas oublier de contacter des gens succeptible de souscrire). C'est pour √ßa qu'il faudra √©galement prendre en compte le f1-Score qui est l'√©quilibre entre les deux
        - A ce stade de l'√©tude, le mod√®le SVC semble le plus performant avec tr√®s peu de faux positifs et un bon score F1
        """, unsafe_allow_html = True)

        # D√©tails par mod√®le
        st.subheader("D√©tails par mod√®le")
        if st.checkbox("Afficher le d√©tail par mod√®le", value = False):

            selected_model = st.selectbox("Choisir un mod√®le", options = list(models.keys()))

            # Affichage des r√©sultats du mod√®le s√©lectionn√©
            st.markdown(f"**Rapport de classification ‚Äì {selected_model}**")
            st.text(reports[selected_model])

            # Matrice de confusion
            fig, ax = plt.subplots(figsize = (4, 3))  # taille r√©elle du canvas
            disp = ConfusionMatrixDisplay(
                confusion_matrix = matrices[selected_model],
                display_labels = models[selected_model].classes_
            )
            disp.plot(ax = ax, cmap = plt.cm.Blues, colorbar = False)
            plt.tight_layout()

            # Enregistrer en m√©moire
            buf = BytesIO()
            fig.savefig(buf, format = "png", dpi = 100, bbox_inches = "tight")
            buf.seek(0)
            plt.close(fig)

            # Affichage retravaill√©
            st.image(buf, caption = f"Matrice de confusion ‚Äì {selected_model}", use_container_width = False)

        st.subheader("Interpr√©tation des r√©sultats")
        st.markdown("""
        Suite aux conclusions des diff√©rentes approches, nous avons d√©cid√© d'appliquer les optimisations suivantes :
        - Modification des param√®tres de profondeur pour √©viter que le mod√®le surapprend
        - Ajustement du nombre d'√©chantillons minimum par feuille pour rendre le mod√®le moins complexe
            - DecisionTree : max_depth=10, min_samples_leaf=10
            - RandomForrest : n_estimators=100, max_depth=15, min_samples_leaf=5
        - Ajout de mod√®les suppl√©mentaires
                    """)
        
        st.subheader("R√©sultats apr√®s premiers ajustements")
        # Affichage des r√©sultats apr√®s optimisation
        results_df_optim, _, _, _ = evaluate_models_optimisation()
        st.dataframe(results_df_optim, use_container_width = True)
        st.markdown("""
        On peut tout de suite constater que les r√©sultats sont meilleurs, 
        et que nous avons r√©duit l'overfitting des mod√®les Decision Tree et Random Forest.
        Le nouveau modele Gradient Boosting test√© semble √©galement tr√®s prometteur.
                    """)
        
        # Importance features sur le meilleur mod√®le
        st.subheader("Affichage des importances features sur Gradient Boosting")
        if st.checkbox("Afficher les features importantes", value = False):
            importance_features()


    with tab2:

        # Cr√©ation d'un outil pour tester manuellement plusieurs configurations possibles
        st.header("Mod√©lisation personnalis√©e")
        colA, colB = st.columns(2)

        with colA:
            st.subheader("Conclusions et modifications")
            st.markdown("""
            Dans cette section, nous allons affiner notre mod√®le en appliquant les optimisations suivantes :
            - Suppression de variables √† faible impact (`contact`)  
            - Encodage cyclique pour les `mois` et `jours`  
            - Transformation de `previous` en `contacted_before` (bool√©en)  
            """)

        with colB:
            st.subheader("Pr√©sentation de l'outil")
            st.markdown("""
            Vous pouvez utiliser l'outil ci-dessous pour :
            - Choisir un mod√®le parmi une liste  
            - S√©lectionner les param√®tres du mod√®le  
            - Entra√Æner le mod√®le  
            - Afficher les r√©sultats (accuracy, precision, recall, f1-score)  
            - Sauvegarder les r√©sultats dans un tableau r√©capitulatif  
            - R√©initialiser le tableau r√©capitulatif  
            """)

        st.markdown("---")
        st.subheader("Entra√Ænement de mod√®les personnalis√©s")
        # Initialisation
        if "results_df" not in st.session_state:
            st.session_state["results_df"] = pd.DataFrame(columns = ["Mod√®le", "Param√®tres", "Accuracy", "Precision", "Recall", "F1"])
        for metric in ["acc", "prec", "rec", "f1"]:
            if metric not in st.session_state:
                st.session_state[metric] = None

        # Chargement des donn√©es
        X_train, X_test, y_train, y_test = ready_to_process_data_advanced()

        # Mod√®le et param√®tres par d√©faut
        model_options = ["Logistic Regression", "SVM", "Random Forest v2", "Decision Tree v2", "Gradient Boosting"]
        model_choice = st.selectbox("Choisissez un mod√®le :", model_options)

        params = {}

        param_col1, param_col2 = st.columns(2)

        if model_choice == "Logistic Regression":
            with param_col1:
                C = st.selectbox("C (Regularization)", [0.01, 0.1, 1, 10], index = 2)
            with param_col2:
                class_weight = st.selectbox("Class Weight", ["balanced", None])
            params = {"C": C, "class_weight": class_weight, "max_iter": 1000, "random_state": 48}
            model = LogisticRegression(**params)

        elif model_choice == "SVM":
            with param_col1:
                kernel = st.selectbox("Kernel", ["rbf", "linear", "poly"])
            with param_col2:
                C = st.selectbox("C (Regularization)", [0.1, 1, 10])
            params = {"kernel": kernel, "C": C, "random_state": 48}
            model = SVC(**params)

        elif model_choice == "Random Forest v2":
            with param_col1:
                n_estimators = st.selectbox("n_estimators", [50, 100, 200], index = 1)
                max_depth = st.selectbox("max_depth", [5, 10, 15])
            with param_col2:
                min_samples_leaf = st.selectbox("min_samples_leaf", [5, 10, 15])
            params = {
                "n_estimators": n_estimators, "max_depth": max_depth,
                "min_samples_leaf": min_samples_leaf, "random_state": 48
            }
            model = RandomForestClassifier(**params)

        elif model_choice == "Decision Tree v2":
            with param_col1:
                max_depth = st.selectbox("max_depth", [5, 10, 15])
            with param_col2:
                min_samples_leaf = st.selectbox("min_samples_leaf", [5, 10, 15])
            params = {"max_depth": max_depth, "min_samples_leaf": min_samples_leaf, "random_state": 48}
            model = DecisionTreeClassifier(**params)

        elif model_choice == "Gradient Boosting":
            with param_col1:
                n_estimators = st.selectbox("n_estimators", [50, 100, 200], index = 1)
                learning_rate = st.selectbox("learning_rate", [0.01, 0.05, 0.1], index = 1)
            with param_col2:
                max_depth = st.selectbox("max_depth", [3, 5, 7])
                min_samples_split = st.selectbox("min_samples_split", [10, 20, 30])
                min_samples_leaf = st.selectbox("min_samples_leaf", [5, 10, 15])
            params = {
                "n_estimators": n_estimators, "learning_rate": learning_rate,
                "max_depth": max_depth, "min_samples_split": min_samples_split,
                "min_samples_leaf": min_samples_leaf, "random_state": 48
            }
            model = GradientBoostingClassifier(**params)

        # Entra√Ænement
        if st.button("Entra√Æner le mod√®le"):
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)

            st.session_state["acc"] = accuracy_score(y_test, y_pred)
            st.session_state["prec"] = precision_score(y_test, y_pred, pos_label = 1)
            st.session_state["rec"] = recall_score(y_test, y_pred, pos_label = 1)
            st.session_state["f1"] = f1_score(y_test, y_pred, pos_label = 1)

        st.markdown("---")

        # Affichage des r√©sultats
        if st.session_state["acc"] is not None:
            st.subheader("R√©sultats")
            st.write(f"**Accuracy :** {st.session_state['acc']:.4f}")
            st.write(f"**Precision (classe 1) :** {st.session_state['prec']:.4f}")
            st.write(f"**Recall (classe 1) :** {st.session_state['rec']:.4f}")
            st.write(f"**F1-score (classe 1) :** {st.session_state['f1']:.4f}")

        # Bouton sauvegarder pour mettre les r√©sultats dans un dataframe
        if st.button("üíæ Sauvegarder les r√©sultats"):
            if st.session_state["acc"] is not None:
                param_str = ", ".join(f"{k}={v}" for k, v in params.items())
                new_result = {
                    "Mod√®le": model_choice,
                    "Param√®tres": param_str,
                    "Accuracy": st.session_state["acc"],
                    "Precision": st.session_state["prec"],
                    "Recall": st.session_state["rec"],
                    "F1": st.session_state["f1"]
                }
                st.session_state["results_df"] = pd.concat(
                    [st.session_state["results_df"], pd.DataFrame([new_result])],
                    ignore_index = True
                )

        st.markdown("---")

        # Affichage du dataframe avec les r√©sultats sauvegard√©s
        st.subheader("Tableau r√©capitulatif des mod√®les sauvegard√©s")
        st.dataframe(st.session_state["results_df"])

        # Affichage du bouton effacer pour vider le dataframe
        if st.button("üßπ Effacer la table des r√©sultats"):
            st.session_state["results_df"] = pd.DataFrame(columns = ["Mod√®le", "Param√®tres", "Accuracy", "Precision", "Recall", "F1"])
            st.success("Tableau r√©initialis√©.")